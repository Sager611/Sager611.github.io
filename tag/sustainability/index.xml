<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sustainability | Adri√°n Sager La Ganga</title>
    <link>https://sager611.github.io/tag/sustainability/</link>
      <atom:link href="https://sager611.github.io/tag/sustainability/index.xml" rel="self" type="application/rss+xml" />
    <description>sustainability</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 25 Feb 2023 16:37:09 +0100</lastBuildDate>
    <image>
      <url>https://sager611.github.io/media/icon_hu4c33f529594115c732c21d26133ca9c2_321136_512x512_fill_lanczos_center_3.png</url>
      <title>sustainability</title>
      <link>https://sager611.github.io/tag/sustainability/</link>
    </image>
    
    <item>
      <title>UQ-based metrics for chemical sustainability</title>
      <link>https://sager611.github.io/project/epfl-master-thesis/</link>
      <pubDate>Sat, 25 Feb 2023 16:37:09 +0100</pubDate>
      <guid>https://sager611.github.io/project/epfl-master-thesis/</guid>
      <description>&lt;p&gt;What if we could systematically quantify &lt;em&gt;how&lt;/em&gt; sustainable a reaction is?&lt;/p&gt;
&lt;p&gt;In this project (my master&amp;rsquo;s thesis at EPFL) I explored how useful it would be if we quantified sustainability as &lt;em&gt;how likely&lt;/em&gt; it is that a reaction is sustainable. This likelihood would then be computed by employing &lt;strong&gt;uncertainty quantification (UQ)&lt;/strong&gt; on some AI model&amp;rsquo;s prediction.&lt;/p&gt;
&lt;p&gt;In this page I collect some of my thoughts derived from this project.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sager611.github.io/uploads/EPFL_Master_Thesis.pdf&#34; target=&#34;_blank&#34;&gt;You can read the full report here.&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This work was created and funded as part of the &lt;a href=&#34;https://nccr-catalysis.ch/news/recipients-of-2022-young-talents-fellowship/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NCCR Catalysis Young Talents Fellowship&lt;/a&gt;, a National Centre of Competence in Research funded by the Swiss National Science Foundation.
  &lt;/div&gt;
&lt;/div&gt;


&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#ai-metric-definition&#34;&gt;AI-metric definition&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#quantifying-ai-metrics&#34;&gt;Quantifying AI-metrics&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;ai-metric-definition&#34;&gt;AI-metric definition&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s say a chemical reaction can be one of 

$\mathcal{C}$ classes, for ex., according to its type: &amp;ldquo;&lt;em&gt;carboxylic acid to acid chloride&lt;/em&gt;&amp;rdquo;, &amp;ldquo;&lt;em&gt;translocase-catalyzed&lt;/em&gt;&amp;rdquo;, etc.&lt;/p&gt;
&lt;p&gt;Some of these classes are sustainable, 

$\mathcal{C}_\text{sust}$, some are not, 

$\mathcal{C}_\text{non-sust}$, and we may have an unrecognized class, 

$\mathcal{C}_\text{unrec}=\{y_\text{unrec}\}$.&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-7&#34;&gt;
  &lt;summary&gt;Click to view the reaction type distribution&lt;/summary&gt;
  &lt;p&gt;&lt;figure  id=&#34;figure-in-reality-our-distribution-of-reaction-types-is-hierarchical-but-the-argument-still-applies&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;rxn_class_distr.svg&#34; alt=&#34;Reaction classes are divided in multiple levels&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      In reality, our distribution of reaction types is hierarchical, but the argument still applies
    &lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;We can then quantify &lt;em&gt;how likely&lt;/em&gt; we &lt;em&gt;expect&lt;/em&gt; some reaction 

$\pmb{x}$ to be of some class 

$y\in\mathcal{C}$:&lt;/p&gt;


$$ \text{AI-metric}_y := \mathbb{E}_{p(\pmb{\theta}\vert\mathcal{D})}\left[p(y\vert\pmb{x}, \pmb{\theta})\right]\cdot\text{confidence}(\pmb{x}, y) \quad \in [0,1]$$
&lt;p&gt;Where 

$\pmb{\theta}$ are the parameters of our AI model after training it on some dataset 

$\mathcal{D}$.&lt;/p&gt;
&lt;p&gt;Note how we are scaling by how &lt;em&gt;confident&lt;/em&gt; we are that this expected likelihood is correct. In our case,&lt;/p&gt;


$$\text{confidence}(\pmb{x}, y) := 1 - 2\cdot\text{stddev}_{p(\pmb{\theta}\vert\mathcal{D})}\big(p(y\vert\pmb{x}, \pmb{\theta})\big)$$
&lt;p&gt;Which is always in 

$[0,1]$ since probabilities cannot deviate more than 

$1/2$.&lt;/p&gt;
&lt;p&gt;But, how do we score how likely our 

$\pmb{x}$ is of &lt;em&gt;any&lt;/em&gt; class in 

$\mathcal{C}_\text{sust}$?&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-arrow-right  pr-1 fa-fw&#34;&gt;&lt;/i&gt; We simply take the maximum over 

$\mathcal{C}_\text{sust}$:&lt;/p&gt;


$$\text{AI-metric} := \max_{y\in\mathcal{C}_\text{sust}} \text{AI-metric}_y \quad \in [0, 1] $$
&lt;details class=&#34;spoiler &#34; id=&#34;spoiler-21&#34;&gt;
  &lt;summary&gt;Why not sum over

$\mathcal{C}_\text{sust}$?&lt;/summary&gt;
  &lt;p&gt;Formally, we are asking 

$p(\cup_{\mathcal{C}_\text{sust}}y\vert \pmb{x},\mathcal{D})$, which is:


$$ \max_{y\in\mathcal{C}_\text{sust}} p(y\vert\pmb{x},\mathcal{D}) \leq p(\cup_{\mathcal{C}_\text{sust}}y\vert \pmb{x},\mathcal{D}) \leq \sum_{y\in\mathcal{C}_\text{sust}} p(y\vert\pmb{x},\mathcal{D}) $$
    Since we are estimating our metric (see next section) and since some 

$\pmb{x}$ may be of multiple classes, if we sum probabilities we would be overestimating the true value and also our score may end up above 1. &lt;br/&gt;
    It is also crucial that in our case our AI model is &lt;em&gt;single-label&lt;/em&gt;, so it is designed to only predict the highest probability class.
  &lt;/p&gt;
&lt;/details&gt;
&lt;h3 id=&#34;quantifying-ai-metrics&#34;&gt;Quantifying AI-metrics&lt;/h3&gt;
&lt;p&gt;Without getting too philosophical, we want to believe that &lt;em&gt;for sure&lt;/em&gt; there is some underlying &lt;em&gt;true&lt;/em&gt; classification set for an input 

$\pmb{x}$, 

$\mathcal{C}_\text{true} \subseteq \mathcal{C}$, so:&lt;/p&gt;


$$
p(y\vert\pmb{x}) = \begin{cases}1 &amp; \text{if }y\in\mathcal{C}_\text{true} \\
0 &amp; \text{o.w.}\end{cases}
$$
&lt;p&gt;Note that (by our philosophy) 

$p(y\vert\pmb{x})$ is equivalent to 

$p(y\vert\pmb{x},\mathcal{D}_\text{all})$ where 

$\mathcal{D}_\text{all}$ is all the knowledge of the universe (quite some information!).&lt;/p&gt;
&lt;p&gt;Of course, in reality at best we know:&lt;/p&gt;


$$p(y\vert\pmb{x},\mathcal{D}) = \mathbb{E}_{p(\pmb{\theta}\vert\mathcal{D})}\left[ p(y\vert\pmb{x},\pmb{\theta}) \right]$$
&lt;p&gt;For our observed training set 

$\mathcal{D}$.&lt;/p&gt;
&lt;p&gt;This introduces two sources of uncertainty:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Epistemic&lt;/strong&gt; 

$\pmb{\theta}$: due to the limited expresiveness of our model and its optimization procedure.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;We efficiently quantify it with &lt;strong&gt;Monte Carlo Dropout (MCDropout)&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Aleatoric&lt;/strong&gt; 

$\mathcal{D}$: due to noise in our training set (some entries aren&amp;rsquo;t reactions or have a wrong label).&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;We efficiently quantify it with &lt;strong&gt;test-time data augmentation&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>
