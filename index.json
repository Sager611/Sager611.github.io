
    
    
    
    [{"authors":null,"categories":null,"content":"I am currently interested in methods for causal inference, explainable AI, and program inference.\nDuring my master‚Äôs degree at EPFL, I have carried out multiple projects on applied machine learning, such as employing autoencoders to predict stellar properties at the astrophysics laboratory and exploring computer vision methods for image registration of a fly‚Äôs neuron activations in Pavan Ramdya‚Äôs Lab. Finally, during my thesis at IBM Research in Z√ºrich, I applied NLP methods, uncertainty quantification, and explainable AI techniques to quantify chemical sustainability.\nI enjoy hiking ‚õ∞, playing the piano üéπ, watching old movies üìΩ, and learning both about philosophy and the newest tech!\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am currently interested in methods for causal inference, explainable AI, and program inference.\nDuring my master‚Äôs degree at EPFL, I have carried out multiple projects on applied machine learning, such as employing autoencoders to predict stellar properties at the astrophysics laboratory and exploring computer vision methods for image registration of a fly‚Äôs neuron activations in Pavan Ramdya‚Äôs Lab.","tags":null,"title":"Adri√°n Sager La Ganga","type":"authors"},{"authors":[],"categories":[],"content":" In 2020 I was following lectures on automatic control and learned about the transfer function of a system and ways to visualize it, at which point I was curious so I went ahead and wrote a simple visualizer for generic transfer functions.\nYou can jump ahead to the visualizer.\nSetup The basic idea is that we can build a system with a feedback loop that takes an input signal $x(t)$ and outputs another signal $y(t)$:\nWe then focus on linear time-invariant (LTI) transformations, which in a few words are those which take as input $e(t)$ and output $y(t) = (e \\ast h)(t)$, where $h(t)$ is called the impulse response since it is exactly the value of the output $y(t)$ if our input where an impulse $e(t)=\\delta(t)$.\nIn the Laplace function space, the convolution of our transformation becomes a multiplication $Y(s) = H(s)E(s)$.\nLet‚Äôs plug in our $H(s)$ in the feedback loop!\nWe recursively apply it so we end up with:\n$$ \\begin{align*} Y(s) \u0026amp;= \\left( H(s) + H(s)^2 + H(s)^3 + \\dots \\right) \\cdot X(s) \\\\ \u0026amp;= \\frac{H(s)}{1 - H(s)} \\cdot X(s) \\end{align*} $$ Visualizer Note that if our $H(s)$ touches the value 1 we‚Äôll end up with an $\\infty$, oops.\nSo, when designing $H(s)$ we want to make sure that it is some distance away from 1.\nBut $H: \\mathbb{C} \\rightarrow \\mathbb{C}$, how can we visualize it?\nWell, there are multiple approaches and this is where I got curious and decided to write a visualizer in p5.js. I included a cartesian plot and a Nichols plot. Other common plots include Bode and Nyquist.\nI also included a simple abstract syntax tree (AST) parser and traversal so you can write any $H(s)$ you want and see what happens!\nYou can try it out right here:\nControls:\nDrag to move around.\nMouse wheel to zoom in/out.\nSpace to reset offset.\nYou may encounter some bugs if you introduce incorrect\n$H(s)$ and the visualizer may crash. Use with care.\n","date":1677513077,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677513077,"objectID":"dfbdef4f447a336c3440bf8fb1e9da0a","permalink":"https://sager611.github.io/post/p5js-vis-transfer-function/","publishdate":"2023-02-27T16:51:17+01:00","relpermalink":"/post/p5js-vis-transfer-function/","section":"post","summary":"In 2020 I was following lectures on automatic control and learned about the transfer function of a system and ways to visualize it, at which point I was curious so I went ahead and wrote a simple visualizer for generic transfer functions.","tags":["p5js","control theory"],"title":"Visualizing transfer functions in p5.js","type":"post"},{"authors":[],"categories":[],"content":" What if we could systematically quantify how sustainable a reaction is?\nIn this project (my master‚Äôs thesis at EPFL) I explored how useful it would be if we quantified sustainability as how likely it is that a reaction is sustainable. This likelihood would then be computed by employing uncertainty quantification (UQ) on some AI model‚Äôs prediction.\nThe main contribution of the project is an extensible toolkit with sustainability metrics based on AI model predictions.\nIn this page I collect some of my thoughts derived from this project.\nYou can read the full report here.\nThis work was created and funded as part of the NCCR Catalysis Young Talents Fellowship, a National Centre of Competence in Research funded by the Swiss National Science Foundation. Table of Contents AI-metric definition Modelling uncertainty Quantifying AI-metrics Validating AI-metrics Don‚Äôt pay attention to the attention ‚Ä¶ Putting it all together AI-metric definition Let‚Äôs say a chemical reaction can be one of $\\mathcal{C}$ classes, for ex., according to its type: ‚Äúcarboxylic acid to acid chloride‚Äù, ‚Äútranslocase-catalyzed‚Äù, etc.\nSome of these classes are sustainable, $\\mathcal{C}_\\text{sust}$, some are not, $\\mathcal{C}_\\text{non-sust}$, and we may have an unrecognized class, $\\mathcal{C}_\\text{unrec}=\\{y_\\text{unrec}\\}$.\nClick to view the reaction type distribution In reality, our distribution of reaction types is hierarchical, but the argument still applies We can then quantify how likely we expect some reaction $\\pmb{x}$ to be of some class $y\\in\\mathcal{C}$:\n$$ \\text{AI-metric}_y := \\mathbb{E}_{p(\\pmb{\\theta}\\vert\\mathcal{D})}\\left[p(y\\vert\\pmb{x}, \\pmb{\\theta})\\right]\\cdot\\text{confidence}(\\pmb{x}, y) \\quad \\in [0,1]$$ Where $\\pmb{\\theta}$ are the parameters of our AI model after training it on some dataset $\\mathcal{D}$.\nNote how we are scaling by how confident we are that this expected likelihood is correct. In our case,\n$$\\text{confidence}(\\pmb{x}, y) := 1 - 2\\cdot\\text{stddev}_{p(\\pmb{\\theta}\\vert\\mathcal{D})}\\big(p(y\\vert\\pmb{x}, \\pmb{\\theta})\\big)$$ Which is always in $[0,1]$ since probabilities cannot deviate more than $1/2$.\nBut, how do we score how likely our $\\pmb{x}$ is of any class in $\\mathcal{C}_\\text{sust}$?\nWe simply take the maximum over $\\mathcal{C}_\\text{sust}$:\n$$\\text{AI-metric} := \\max_{y\\in\\mathcal{C}_\\text{sust}} \\text{AI-metric}_y \\quad \\in [0, 1] $$ Why not sum over $\\mathcal{C}_\\text{sust}$? Formally, we are asking $p(\\cup_{\\mathcal{C}_\\text{sust}}y\\vert \\pmb{x},\\mathcal{D})$, which is: $$ \\max_{y\\in\\mathcal{C}_\\text{sust}} p(y\\vert\\pmb{x},\\mathcal{D}) \\leq p(\\cup_{\\mathcal{C}_\\text{sust}}y\\vert \\pmb{x},\\mathcal{D}) \\leq \\sum_{y\\in\\mathcal{C}_\\text{sust}} p(y\\vert\\pmb{x},\\mathcal{D}) $$ Since we are estimating our metric (see next section) and since some $\\pmb{x}$ may be of multiple classes, if we sum probabilities we would be overestimating the true value and also our score may end up above 1. It is also crucial that in our case our AI model is single-label, so it is designed to only predict the highest probability class. Modelling uncertainty Without getting too philosophical, we want to believe that for sure there is some underlying true classification set for an input $\\pmb{x}$, $\\mathcal{C}_\\text{true} \\subseteq \\mathcal{C}$, so:\n$$ p(y\\vert\\pmb{x}) = \\begin{cases}1 \u0026amp; \\text{if }y\\in\\mathcal{C}_\\text{true} \\\\ 0 \u0026amp; \\text{o.w.}\\end{cases} $$ Note that (by our philosophy) $p(y\\vert\\pmb{x})$ is equivalent to $p(y\\vert\\pmb{x},\\mathcal{D}_\\text{all})$ where $\\mathcal{D}_\\text{all}$ is all the knowledge of the universe (quite some information!).\nOf course, in reality at best we know:\n$$p(y\\vert\\pmb{x},\\mathcal{D}) = \\mathbb{E}_{p(\\pmb{\\theta}\\vert\\mathcal{D})}\\left[ p(y\\vert\\pmb{x},\\pmb{\\theta}) \\right]$$ For our observed training set $\\mathcal{D}$.\nThis means that we are in the presence of two sources of uncertainty1:\nEpistemic $\\pmb{\\theta}$: due to the limited expresiveness of our model and its optimization procedure. Aleatoric $\\mathcal{D}$: due to noise in our training set (some entries aren‚Äôt reactions or have a wrong label). Quantifying AI-metrics We use efficient uncertainty quantification (UQ) techniques to estimate our AI-metric according to the two sources of uncertainty2:\nMonte Carlo Dropout (MCDropout) for epistemic uncertainty $\\pmb{\\theta}$: We leave our Drouput layers on during inference, so for each forward pass on the same $\\pmb{x}$ we are effectively sampling different submodels from an ensemble.\nTest-time data augmentation for aleatoric uncertainty $\\mathcal{D}$: We augment $\\pmb{x}$ during inference.\nWe then have $N\\times M$ likelihoods $p(y\\vert\\pmb{x}^{(i)}, \\pmb{\\theta}^{(j)})$ where we sampled our input $\\pmb{x}^{(1)},\\dots,\\pmb{x}^{(N)}$ and our model $\\pmb{\\theta}^{(1)},\\dots,\\pmb{\\theta}^{(M)}$. Our AI-metric then simply uses the average and stddev of these values to compute its score.\nFor example,\nTop-5 reaction types for reaction according to the AI-metric. The actual true types for ‚Ä¶","date":1677339429,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677339429,"objectID":"bb373e34aa74a9e0f96d626986715a37","permalink":"https://sager611.github.io/project/epfl-master-thesis/","publishdate":"2023-02-25T16:37:09+01:00","relpermalink":"/project/epfl-master-thesis/","section":"project","summary":"What if we could systematically quantify how sustainable a reaction is?\nIn this project (my master‚Äôs thesis at EPFL) I explored how useful it would be if we quantified sustainability as how likely it is that a reaction is sustainable.","tags":["UQ","NLP","chemistry","sustainability"],"title":"UQ-based metrics for chemical sustainability","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://sager611.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]